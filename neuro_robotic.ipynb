{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo: \n",
    "\n",
    "* motor-ansteurerung so bauen wir im ursprünglichem experiment\n",
    "* mehr schreiben was die step funktion macht\n",
    "\n",
    "(ignore this cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neurorobotik with PyNN and PyBullet\n",
    "\n",
    "In this Notebook we will build and execute a neuro-robotics experiment. Für the neural simulation we will use [PyNN](https://neuralensemble.org/PyNN/) and [Nest](https://www.nest-initiative.org/?page=Software). For the simulation of the physic we use [PyBullet](https://github.com/bulletphysics/bullet3/tree/master/examples/pybullet). \n",
    "\n",
    "This experiment is a re-creation of the [braitenberg-husky-experiment](https://bitbucket.org/hbpneurorobotics/experiments/src/development/braitenberg_husky/) in the neurorobotics plattform of the human brain project. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing all modules we will use in this notebook. Make sure to install only python**3**-versions of all dependencies. \n",
    "\n",
    "You can not just install these via pip:\n",
    "\n",
    "- _pybullet_ needs to be installed from source to get numpy-support. Otherwise it will be slower, and getCameraImage doesn't return a numpy-array. \n",
    "- _nest_ can only be installed from source. We must use version 2.16, because the current master is not yet compatible with _pynn_. Also _nest_ is compiled with _libnreuosim_, which needs a workaround until [the PR](https://github.com/nest/nest-simulator/pull/1235) is merged. I'm not 100% certain if _libneurosim_ is even required for this project, but _nest_ gives a warning if it's missing, so we will install it. \n",
    "- there is a warning \"UserWarning: Unable to install NEST extensions. Certain models may not be available\", which doesn't seem to affect this project. Please ignore it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pyNN/nest/__init__.py:55: UserWarning: Unable to install NEST extensions. Certain models may not be available.\n",
      "Further details: DynamicModuleManagementError in Install: Module 'pynn_extensions' could not be opened.\n",
      "The dynamic loader returned the following error: 'file not found'.\n",
      "\n",
      "Please check LD_LIBRARY_PATH (OSX: DYLD_LIBRARY_PATH)!\n",
      "  warnings.warn(\"Unable to install NEST extensions. Certain models may not be available.\\nFurther details: {}\".format(err))\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import pybullet as p\n",
    "import pybullet_data\n",
    "\n",
    "import pyNN.nest as brain_sim\n",
    "from pyNN.utility import get_simulator, normalized_filename\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import animation\n",
    "from pyNN.utility.plotting import Figure, Panel\n",
    "from quantities import mV\n",
    "\n",
    "if not p.isNumpyEnabled():\n",
    "    raise Exception(\"pybullet must be compiled with numpy-support for this projet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### brain sim mit pynn\n",
    "\n",
    "first we define the population in pynn. This code is copied from [braitenberg.py on hbpneurorobotics](https://bitbucket.org/hbpneurorobotics/models/src/development/brains/braitenberg.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pop():\n",
    "    sim = brain_sim\n",
    "    SENSORPARAMS = {'v_rest': -60.5,\n",
    "                    'cm': 0.025,\n",
    "                    'tau_m': 10.,\n",
    "                    'tau_refrac': 10.0,\n",
    "                    'tau_syn_E': 2.5,\n",
    "                    'tau_syn_I': 2.5,\n",
    "                    'e_rev_E': 0.0,\n",
    "                    'e_rev_I': -75.0,\n",
    "                    'v_thresh': -60.0,\n",
    "                    'v_reset': -60.5}\n",
    "\n",
    "    GO_ON_PARAMS = {'v_rest': -60.5,\n",
    "                    'cm': 0.025,\n",
    "                    'tau_m': 10.0,\n",
    "                    'e_rev_E': 0.0,\n",
    "                    'e_rev_I': -75.0,\n",
    "                    'v_reset': -61.6,\n",
    "                    'v_thresh': -60.51,\n",
    "                    'tau_refrac': 10.0,\n",
    "                    'tau_syn_E': 2.5,\n",
    "                    'tau_syn_I': 2.5}\n",
    "\n",
    "    population = sim.Population(8, sim.IF_cond_alpha())\n",
    "    population[0:5].set(**SENSORPARAMS)\n",
    "    population[5:6].set(**GO_ON_PARAMS)\n",
    "    population[6:8].set(**SENSORPARAMS)\n",
    "\n",
    "    syn_params = {'U': 1.0, 'tau_rec': 1.0, 'tau_facil': 1.0}\n",
    "\n",
    "    # Synaptic weights\n",
    "    WEIGHT_RED_TO_ACTOR = 1.5e-4\n",
    "    WEIGHT_RED_TO_GO_ON = 1.2e-3  # or -1.2e-3?\n",
    "    WEIGHT_GREEN_BLUE_TO_ACTOR = 1.05e-4\n",
    "    WEIGHT_GO_ON_TO_RIGHT_ACTOR = 1.4e-4\n",
    "    DELAY = 1\n",
    "\n",
    "    # Connect neurons\n",
    "    CIRCUIT = population\n",
    "\n",
    "    SYN = sim.TsodyksMarkramSynapse(weight=abs(WEIGHT_RED_TO_ACTOR),\n",
    "                                    delay=DELAY, **syn_params)\n",
    "    sim.Projection(presynaptic_population=CIRCUIT[2:3],\n",
    "                   postsynaptic_population=CIRCUIT[7:8],\n",
    "                   connector=sim.AllToAllConnector(),\n",
    "                   synapse_type=SYN,\n",
    "                   receptor_type='excitatory')\n",
    "    sim.Projection(presynaptic_population=CIRCUIT[3:4],\n",
    "                   postsynaptic_population=CIRCUIT[6:7],\n",
    "                   connector=sim.AllToAllConnector(),\n",
    "                   synapse_type=SYN,\n",
    "                   receptor_type='excitatory')\n",
    "\n",
    "\n",
    "    SYN = sim.TsodyksMarkramSynapse(weight=abs(WEIGHT_RED_TO_GO_ON),\n",
    "                                    delay=DELAY, **syn_params)\n",
    "    sim.Projection(presynaptic_population=CIRCUIT[0:2],\n",
    "                   postsynaptic_population=CIRCUIT[4:5],\n",
    "                   connector=sim.AllToAllConnector(),\n",
    "                   synapse_type=SYN,\n",
    "                   receptor_type='inhibitory')\n",
    "    sim.Projection(presynaptic_population=CIRCUIT[0:2],\n",
    "                   postsynaptic_population=CIRCUIT[5:6],\n",
    "                   connector=sim.AllToAllConnector(),\n",
    "                   synapse_type=SYN,\n",
    "                   receptor_type='inhibitory')\n",
    "\n",
    "    SYN = sim.TsodyksMarkramSynapse(weight=abs(WEIGHT_GREEN_BLUE_TO_ACTOR),\n",
    "                                    delay=DELAY, **syn_params)\n",
    "    sim.Projection(presynaptic_population=CIRCUIT[4:5],\n",
    "                   postsynaptic_population=CIRCUIT[7:8],\n",
    "                   connector=sim.AllToAllConnector(),\n",
    "                   synapse_type=SYN,\n",
    "                   receptor_type='excitatory')\n",
    "\n",
    "    SYN = sim.TsodyksMarkramSynapse(weight=abs(WEIGHT_GO_ON_TO_RIGHT_ACTOR),\n",
    "                                    delay=DELAY, **syn_params)\n",
    "    sim.Projection(presynaptic_population=CIRCUIT[5:6],\n",
    "                   postsynaptic_population=CIRCUIT[7:8],\n",
    "                   connector=sim.AllToAllConnector(),\n",
    "                   synapse_type=SYN,\n",
    "                   receptor_type='excitatory')\n",
    "\n",
    "    return population    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next we set up the input for the population. For this we create two poisson spike generators and hook them up to the population according to original project. The values for the projections come from in the first 6 lines of [this file](https://bitbucket.org/hbpneurorobotics/experiments/src/development/braitenberg_husky/eye_sensor_transmit.py) and the parameters for the new neurons come are the [default values for PoissonSpikeGenerators](https://bitbucket.org/hbpneurorobotics/cle/src/development/hbp_nrp_cle/hbp_nrp_cle/brainsim/pynn/devices/__PyNNPoissonSpikeGenerator.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikeGenerator(object):\n",
    "    \"\"\"the class handles the input for the brain\"\"\"\n",
    "    min_rate = 0.0005\n",
    "    def __init__(self, population, interval=20.0, count_red_left=1/3, count_red_right=1/3, count_non_red=1/3):\n",
    "        params_source=  {'start': 0.0, 'duration': float(\"inf\"), 'rate': 0.0}\n",
    "        params_connec= {'weight':0.00015, 'receptor_type':'excitatory','delay':0.1}\n",
    "        self.ssp_red_left_eye = brain_sim.create(brain_sim.SpikeSourcePoisson,  params_source)\n",
    "        self.ssp_red_right_eye = brain_sim.create(brain_sim.SpikeSourcePoisson,  params_source)\n",
    "        self.ssp_green_blue_eye = brain_sim.create(brain_sim.SpikeSourcePoisson,  params_source)\n",
    "        brain_sim.connect(self.ssp_red_left_eye, population[slice(0, 3, 2)], **params_connec)\n",
    "        brain_sim.connect(self.ssp_red_right_eye, population[slice(1, 4, 2)], **params_connec)\n",
    "        brain_sim.connect(self.ssp_green_blue_eye, population[4], **params_connec)\n",
    "    \n",
    "    def set_rates_from_image(self, img):\n",
    "        ratio = self._get_red_ration_from_image(img)\n",
    "        self._set_rates_from_ratios(*ratio)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _get_red_ration_from_image(img):\n",
    "        \"\"\"detect left red and right red like nrp\n",
    "        pixelformat is guessed, but it seems to work.\n",
    "        this functions tries to reproduce https://developer.humanbrainproject.eu/docs/projects/hbp-nrp-cle/1.1.5/codedoc/hbp_nrp_cle.tf_framework.html#hbp_nrp_cle.tf_framework.tf_lib.detect_red\"\"\"\n",
    "        w = img[0]  # width of the image, in pixels\n",
    "        h = img[1]  # height of the image, in pixels\n",
    "        rgb_buffer = img[2]  # color data RGB\n",
    "        # dep_buffer = img_arr[3]  # depth data\n",
    "        count_red_right = 0\n",
    "        count_red_left = 0\n",
    "        count_non_red = 0\n",
    "        for y in range(h):\n",
    "            for x in range(w):\n",
    "                # numpy image\n",
    "                r, g, b, a = (rgb_buffer[y][x][0], rgb_buffer[y][x][1], rgb_buffer[y][x][2], rgb_buffer[y][x][3])\n",
    "                if r > g and r > b:\n",
    "                    if x > w / 2:\n",
    "                        count_red_right = count_red_right + 1\n",
    "                    else:\n",
    "                        count_red_left = count_red_left + 1\n",
    "                else:\n",
    "                    count_non_red = count_non_red + 1\n",
    "\n",
    "        total = count_red_left + count_red_right + count_non_red\n",
    "        return count_red_left/total, count_red_right/total, count_non_red/total\n",
    "\n",
    "    \n",
    "    def _set_rates_from_ratios(self, count_red_left, count_red_right, count_non_red):\n",
    "        if count_red_left <= self.min_rate:\n",
    "            count_red_left = self.min_rate\n",
    "        if count_red_right <= self.min_rate:\n",
    "            count_red_right = self.min_rate\n",
    "        if count_non_red <= self.min_rate:\n",
    "            count_non_red = self.min_rate\n",
    "        try:\n",
    "            self.ssp_red_left_eye.set(rate=2*2000.0 * count_red_left)\n",
    "            self.ssp_red_right_eye.set(rate=2*2000.0 * count_red_right)\n",
    "            self.ssp_green_blue_eye.set(rate=75.0 * count_non_red)\n",
    "        except StopIteration:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the next class handles the output of the brain. It connects two leaky-integrator neurons tp the output-neurons to convert their spikes into voltages, which we will measure. \n",
    "        \n",
    "        \n",
    "The parameters for these Neurons come from [defaults](https://developer.humanbrainproject.eu/docs/projects/hbp-nrp-cle/1.3.8/modules/hbp_nrp_cle/brainsim/pynn/devices/__PyNNLeakyIntegratorTypes.html), again. The connection to the population come from [line 10 and 11 of this file from the original experiment](https://bitbucket.org/hbpneurorobotics/experiments/src/d6e01275e51e0db8fc341bfe5873cb805d4c5c44/braitenberg_husky/braitenberg_husky_linear_twist.py#lines-10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class OutputGenerator(object):\n",
    "    def __init__(self, population):\n",
    "        LI_create = {'v_thresh': float('inf'),'cm': 1.0,'tau_m': 10.0,'tau_syn_E': 2.,\n",
    "            'tau_syn_I': 2.,'v_rest': 0.0,'v_reset': 0.0,'tau_refrac': 0.1,}\n",
    "        LI_connect = {'weight':0.00015, 'receptor_type':'excitatory','delay':0.1}\n",
    "        self.left = brain_sim.create(brain_sim.IF_curr_alpha, LI_create)\n",
    "        self.right = brain_sim.create(brain_sim.IF_curr_alpha, LI_create)\n",
    "        brain_sim.connect(population[6], self.left, **LI_connect)\n",
    "        brain_sim.connect(population[7],self.right,  **LI_connect)\n",
    "        brain_sim.initialize(self.left, v=self.left.get('v_rest'))\n",
    "        brain_sim.initialize(self.right, v=self.right.get('v_rest'))\n",
    "        self.left.record('v')\n",
    "        self.right.record('v')\n",
    "    \n",
    "    def get_current_voltage(self):\n",
    "        return self._get_current_voltage(self.left), self._get_current_voltage(self.right)\n",
    "    def _get_current_voltage(self, cell):\n",
    "        return cell.get_data('v', clear=True).segments[0].filter(name=\"v\")[0][-1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### physics with PyBullet\n",
    "\n",
    "now lets set up the physical world for the experiment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set up a simple world. It has a generic plane for a floor. And there are two floating rectangles which switch color every couple of seconds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup physics sim with pybullet\n",
    "\n",
    "class World(object):\n",
    "    \"\"\"this class handles the world sans robot\n",
    "    the world is just a plane, with two rectangles, which switch colors every 5000 steps\"\"\"\n",
    "    green = [0, 1, 0, 1]\n",
    "    blue = [0, 0, 1, 1]\n",
    "    red = [1, 0, 0, 1]\n",
    "    count_steps = 0\n",
    "    count_switch = 0\n",
    "    age = 0.0\n",
    "    last_switch = float('-inf')\n",
    "\n",
    "    def __init__(self):\n",
    "        p.setAdditionalSearchPath(pybullet_data.getDataPath())  # used by loadURDF\n",
    "        p.setGravity(0, 0, -10)\n",
    "        p.loadURDF(\"plane.urdf\")\n",
    "        plane_id = p.createCollisionShape(p.GEOM_BOX, halfExtents=[1, 0.25, 1])\n",
    "        plane_vis_id = p.createVisualShape(p.GEOM_BOX, halfExtents=[1, 0.25, 1], rgbaColor=self.blue)\n",
    "        self.planeA = p.createMultiBody(baseCollisionShapeIndex=plane_id, basePosition=[0, 5, 2],\n",
    "                                        baseVisualShapeIndex=plane_vis_id)\n",
    "        self.planeB = p.createMultiBody(baseCollisionShapeIndex=plane_id, basePosition=[0, -5, 2],\n",
    "                                        baseVisualShapeIndex=plane_vis_id)\n",
    "        p.setRealTimeSimulation(0)\n",
    "\n",
    "    def do_step(self):\n",
    "        # PyBullet doesn't track this according to \n",
    "        # [this forum post](https://pybullet.org/Bullet/phpBB3/viewtopic.php?t=12438), \n",
    "        # so we need to track it ourselves\n",
    "        self.age = self.age + p.getPhysicsEngineParameters()['fixedTimeStep']\n",
    "        self.count_steps = self.count_steps + 1\n",
    "        if self.age - self.last_switch > 10:\n",
    "            self.last_switch = self.age\n",
    "            self.count_switch = self.count_switch + 1\n",
    "            if self.count_switch % 2 == 0:\n",
    "                p.changeVisualShape(self.planeA, -1, rgbaColor=self.green)\n",
    "                p.changeVisualShape(self.planeB, -1, rgbaColor=self.red)\n",
    "            else:\n",
    "                p.changeVisualShape(self.planeA, -1, rgbaColor=self.red)\n",
    "                p.changeVisualShape(self.planeB, -1, rgbaColor=self.green)\n",
    "        p.stepSimulation()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a body for the robot. We use [husky](https://clearpathrobotics.com/husky-unmanned-ground-vehicle-robot/), which is a default model both for virtual and real-world robotics experiments. \n",
    "\n",
    "To this body we add a virtual camera, which will feed the brain with input, and drivers for the wheels, which will be controlled by the brain later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Husky(object):\n",
    "    maxForce = 100\n",
    "    targetVelocity = 10\n",
    "\n",
    "    class Camera(object):\n",
    "        init_camera_vector = (1, 0, 0)\n",
    "        init_up_vector = (0, 0, 1)\n",
    "\n",
    "        def __init__(self, pixel_width=80, pixel_height=80, near_plane=0.1, far_plane=100, fov=100):\n",
    "            self.pixel_width = pixel_width\n",
    "            self.pixel_height = pixel_height\n",
    "            self.projection_mat = p.computeProjectionMatrixFOV(\n",
    "                fov, \n",
    "                pixel_width / pixel_height, \n",
    "                near_plane, \n",
    "                far_plane)\n",
    "        \n",
    "        def get_image(self, cam_pos, cam_orientation):\n",
    "            cam_rot = np.array(p.getMatrixFromQuaternion(cam_orientation)).reshape(3, 3)\n",
    "            cam_direction = cam_rot.dot(self.init_camera_vector)\n",
    "            cam_up_vec = cam_rot.dot(self.init_up_vector)\n",
    "            # note: if cam is exactly on joint, getCameraImage freezes sometimes, so we move it a little\n",
    "            # see https://github.com/bulletphysics/bullet3/issues/2297\n",
    "            cam_pos = cam_pos + (cam_direction * 0.5)\n",
    "            cam_target = cam_pos + (cam_direction * 2.0)\n",
    "            view_mat = p.computeViewMatrix(cam_pos, cam_target, cam_up_vec)\n",
    "\n",
    "            return p.getCameraImage(self.pixel_width,\n",
    "                                    self.pixel_height,\n",
    "                                    viewMatrix=view_mat,\n",
    "                                    projectionMatrix=self.projection_mat,\n",
    "                                    flags=p.ER_NO_SEGMENTATION_MASK)\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "        self.camera = Husky.Camera()\n",
    "        self.husky_model = p.loadURDF(\"husky/husky.urdf\",\n",
    "                                      basePosition=[0, 0, 1],\n",
    "                                      baseOrientation=p.getQuaternionFromEuler([0, 0, 0]))\n",
    "\n",
    "        for joint in range(p.getNumJoints(self.husky_model)):\n",
    "            if p.getJointInfo(self.husky_model, joint)[1] == b'user_rail':\n",
    "                self.camera_joint = joint\n",
    "            if p.getJointInfo(self.husky_model, joint)[1] == b'front_left_wheel':\n",
    "                self.front_left_wheel = joint\n",
    "            if p.getJointInfo(self.husky_model, joint)[1] == b'front_right_wheel':\n",
    "                self.front_right_wheel = joint\n",
    "            if p.getJointInfo(self.husky_model, joint)[1] == b'rear_left_wheel':\n",
    "                self.rear_left_wheel = joint\n",
    "            if p.getJointInfo(self.husky_model, joint)[1] == b'rear_right_wheel':\n",
    "                self.rear_right_wheel = joint\n",
    "    \n",
    "    def get_camera_image(self):\n",
    "        joint_pos, joint_orn, _, _, _, _ = p.getLinkState(self.husky_model, self.camera_joint,\n",
    "                                                          computeForwardKinematics=True)\n",
    "        return self.camera.get_image(joint_pos, joint_orn)\n",
    "            \n",
    "    def update_control(self, command_left, command_right):\n",
    "        p.setJointMotorControl2(self.husky_model, self.front_left_wheel, p.VELOCITY_CONTROL,\n",
    "                                targetVelocity=command_left * self.targetVelocity,\n",
    "                                force=self.maxForce)\n",
    "        p.setJointMotorControl2(self.husky_model, self.rear_left_wheel, p.VELOCITY_CONTROL,\n",
    "                                targetVelocity=command_left * self.targetVelocity,\n",
    "                                force=self.maxForce)\n",
    "        p.setJointMotorControl2(self.husky_model, self.front_right_wheel, p.VELOCITY_CONTROL,\n",
    "                                targetVelocity=command_right * self.targetVelocity,\n",
    "                                force=self.maxForce)\n",
    "        p.setJointMotorControl2(self.husky_model, self.rear_right_wheel, p.VELOCITY_CONTROL,\n",
    "                                targetVelocity=command_right * self.targetVelocity,\n",
    "                                force=self.maxForce)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run experiment\n",
    "\n",
    "now that we have defined everything we need, lets boot up experiment.\n",
    "\n",
    "We will work with synchronized timesteps in both the brain simulation and the physics simulation. The default in bullet is [1ms](https://github.com/bulletphysics/bullet3/blob/d220101c5aad92cf7013710b0ed011395cabbb23/examples/pybullet/pybullet.c#L3001). We will be much slower than the defaults. On one hand we only need to update our inputs only a couple of times per seconds. On the other hand the rendering of the robot-images and the updating of the motor-input takes up a significant amount of processing. \n",
    "\n",
    "if the timesteps are too short, the simulation is very slow. If the timesteps are too long, the robot won't notice the red-area until it's too late. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestep_ms = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### initialize the brain simulation \n",
    "\n",
    "<small>Note: the _timestep_ variable in brain_sim.setup() referes to the internal timesteps, and not to the external kind</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_sim.setup(timestep=0.1,min_delay=0.1,max_delay=4.0)\n",
    "population=get_pop()\n",
    "brain_sim.initialize(population, v=population.get('v_rest'))\n",
    "spike_generator = SpikeGenerator(population)\n",
    "output_generator = OutputGenerator(population)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### initialize the physic simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "physicsClient = p.connect(p.DIRECT)  \n",
    "p.setTimeStep(timestep_ms/1000)\n",
    "physic_sim = World()\n",
    "robot = Husky()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### run experiment\n",
    "\n",
    "and now lets to a single step of the simulation. We wrap it in a function, so we can repeat the step at later points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "def step():\n",
    "    physic_sim.do_step()\n",
    "    robot_img = robot.get_camera_image()\n",
    "    spike_generator.set_rates_from_image(robot_img)\n",
    "    brain_sim.run(timestep_ms)\n",
    "    voltage = output_generator.get_current_voltage()\n",
    "    # todo: get better numbers from experiment\n",
    "    commands = np.multiply(np.subtract(voltage, 0.00015),4000)\n",
    "    robot.update_control(commands[0].item(), commands[1].item() )\n",
    "    return voltage, robot_img\n",
    "    \n",
    "step()\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "that was fun, wasn't it? \n",
    "\n",
    "So lets do that again 100 times more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %timeit  -n20 -r5 step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets take a look on what's actually going on in the experiment. \n",
    "\n",
    "We will now set up 3 plots:\n",
    "\n",
    "* the first shows what the robot sees\n",
    "* the second shows how the world outside the robot looks like\n",
    "* the third shows the output-voltage of the brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Invalid alias: The name clear can't be aliased because it is another magic command.\n",
      "ERROR:root:Invalid alias: The name more can't be aliased because it is another magic command.\n",
      "ERROR:root:Invalid alias: The name less can't be aliased because it is another magic command.\n",
      "ERROR:root:Invalid alias: The name man can't be aliased because it is another magic command.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "\n",
    "# get some initial values by doing a single iteration\n",
    "voltages,robot_img = step()\n",
    "\n",
    "\n",
    "# the data looks like the, but it will be empty, because we clear it on every iteration\n",
    "world_view_mat = p.computeViewMatrix([-5, 5, 5], [1, 0, -3], [0, 0, 1])\n",
    "world_projection_mat = p.computeProjectionMatrixFOV(fov=80, aspect=1.0/1.0, nearVal=0.1, farVal=100)\n",
    "world_img = p.getCameraImage(100,100, viewMatrix = world_view_mat, projectionMatrix=world_projection_mat)\n",
    "\n",
    "# setup plots for physic\n",
    "fig = plt.figure()\n",
    "plt.subplot(221)\n",
    "robot_plot = plt.imshow(robot_img[2], interpolation='none')\n",
    "plt.subplot(222)\n",
    "world_plot = plt.imshow(world_img[2], interpolation='none')\n",
    "\n",
    "# setup plots for brain\n",
    "brain_plot = plt.subplot(212)\n",
    "brain_plot_length = 40\n",
    "all_left = np.zeros(brain_plot_length)\n",
    "all_right = np.zeros(brain_plot_length)\n",
    "plt_left = plt.plot(all_left)\n",
    "plt_right = plt.plot(all_right)\n",
    "plt.ylabel(\"Voltage (mV)\")\n",
    "plt.ylim(-0.0001, 0.0009)\n",
    "plt.xlim(0.0, brain_plot_length)\n",
    "\n",
    "\n",
    "def animate(i):    \n",
    "    voltages,robot_img = step()\n",
    "    \n",
    "    update_voltage_plot(voltages)\n",
    "    update_physic_plot(robot_img)\n",
    "\n",
    "def update_physic_plot(robot_img):\n",
    "    robot_plot.set_data(robot_img[2])\n",
    "    world_img = p.getCameraImage(100,100, viewMatrix = world_view_mat, projectionMatrix=world_projection_mat)\n",
    "    world_plot.set_data(world_img[2])\n",
    "\n",
    "def update_voltage_plot(voltages):\n",
    "    global all_left, all_right\n",
    "    all_left = np.append(all_left, voltages[0])\n",
    "    all_right = np.append(all_right, voltages[1])\n",
    "    all_left = np.delete(all_left,0)\n",
    "    all_right = np.delete(all_right,0)\n",
    "    plt_left[0].set_data(np.arange(brain_plot_length),all_left)\n",
    "    plt_right[0].set_data(np.arange(brain_plot_length),all_right)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "anim1 = animation.FuncAnimation(fig, animate, repeat = True, interval=10, frames=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "to start the animation, you may have run the last cell manually once (ctrl+enter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets see if the timing in the brain simulation is still in sync with the time in the physic simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014\n",
      "0.014\n"
     ]
    }
   ],
   "source": [
    "print(brain_sim.get_current_time()/1000)\n",
    "print(physic_sim.age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
