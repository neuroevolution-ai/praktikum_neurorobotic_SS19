{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neurorobotics with PyNN and PyBullet\n",
    "\n",
    "In this Notebook we will build and execute a neuro-robotics experiment. FÃ¼r the neural simulation we will use [PyNN](https://neuralensemble.org/PyNN/) and [Nest](https://www.nest-initiative.org/?page=Software). For the simulation of the physic we use [PyBullet](https://github.com/bulletphysics/bullet3/tree/master/examples/pybullet). \n",
    "\n",
    "This experiment is a re-creation of the [braitenberg-husky-experiment](https://bitbucket.org/hbpneurorobotics/experiments/src/development/braitenberg_husky/) in the neurorobotics plattform of the human brain project. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing all modules we will use in this notebook. Make sure to install only python**3**-versions of all dependencies. \n",
    "\n",
    "You can not just install these via pip:\n",
    "\n",
    "- _pybullet_ needs to be installed from source to get numpy-support. Otherwise it will be slower, and getCameraImage doesn't return a numpy-array. \n",
    "- _nest_ can only be installed from source. We must use version 2.16, because the current master is not yet compatible with _pynn_. Also _nest_ is compiled with _libnreuosim_, which needs a workaround until [the PR](https://github.com/nest/nest-simulator/pull/1235) is merged. I'm not 100% certain if _libneurosim_ is even required for this project, but _nest_ gives a warning if it's missing, so we will install it. \n",
    "- there is a warning \"UserWarning: Unable to install NEST extensions. Certain models may not be available\", which doesn't seem to affect this project. Please ignore it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import csv\n",
    "import random\n",
    "\n",
    "import subprocess\n",
    "import re\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import animation\n",
    "from pyNN.utility.plotting import Figure, Panel\n",
    "from quantities import mV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isFinished(processes):\n",
    "    \n",
    "    for process in processes:\n",
    "        if(process.poll() == None):\n",
    "            return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_min = []\n",
    "error_min = 200\n",
    "number_params = 4\n",
    "number_generations = 20\n",
    "\n",
    "# hyperparameters\n",
    "npop = 50 # population size\n",
    "sigma = 0.1 # noise standard deviation\n",
    "alpha = 0.01 # learning rate\n",
    "\n",
    "# our initial guess is random\n",
    "w = np.random.uniform(low=-4, high=-2, size=(1,number_params))\n",
    "\n",
    "print('w_start: %s' % (str(w)))\n",
    "\n",
    "print(\"Starting\")\n",
    "\n",
    "# start the optimization\n",
    "for generation in range(number_generations):\n",
    "    \n",
    "    # Start time measurement\n",
    "    start = time.time()\n",
    "    \n",
    "    weights_list = []\n",
    "    processes = []\n",
    "    \n",
    "    # Initialize memory for a population of w's, and their rewards\n",
    "    N = np.random.randn(npop, number_params) # samples from a normal distribution N(0,1)\n",
    "    R = np.zeros(npop)\n",
    "    \n",
    "    # Execute all subprocesses and save outputs into files\n",
    "    for i in range(npop):\n",
    "        w_try = w + sigma*N[i] # jitter w using gaussian of sigma 0.1\n",
    "        weights = []\n",
    "        for j in range(number_params):\n",
    "            weights.append( str(10**w_try[0,j]) ) \n",
    "\n",
    "        # Spawn the subprocesses and write outputs into files\n",
    "        filename = \"temp/log\" + str(i) + \".txt\"\n",
    "        with open(filename, \"w\") as file:\n",
    "            command = ['python', 'OptimizationJob_SmallBrain.py']\n",
    "            command.extend(weights)\n",
    "            processes.append( subprocess.Popen(command, stdout=file) ) \n",
    "            \n",
    "        # Append current weights to weights list\n",
    "        weights_list.append(weights)\n",
    "            \n",
    "    # Wait until all subprocesses are finished\n",
    "    while isFinished(processes) == False:\n",
    "        time.sleep(0.5)\n",
    "    \n",
    "    # Read outputs\n",
    "    for i in range(npop):\n",
    "\n",
    "        with open(\"temp/log\" + str(i) + \".txt\") as file:\n",
    "            filetext = file.read()\n",
    "\n",
    "            # Find fitness value through regex\n",
    "            matches = re.findall(\"(.*[^=])=(.*)\", filetext)\n",
    "            error = float(matches[0][1])\n",
    "            R[j] = error\n",
    "            \n",
    "            #print([weights_list[i], error])\n",
    "            \n",
    "            # A new minimum is found\n",
    "            if error < error_min:\n",
    "                error_min = error\n",
    "                print(weights_list[i])\n",
    "                print(error)\n",
    "\n",
    "                \n",
    "    # standardize the rewards to have a gaussian distribution\n",
    "    A = (R - np.mean(R)) / np.std(R)\n",
    "\n",
    "    # perform the parameter update. The matrix multiply below\n",
    "    # is just an efficient way to sum up all the rows of the noise matrix N,\n",
    "    # where each row N[j] is weighted by A[j]\n",
    "    w = w + alpha/(npop*sigma) * np.dot(N.T, A)\n",
    "                \n",
    "    # Time measurement\n",
    "    end = time.time()\n",
    "    \n",
    "    # Ausgabe\n",
    "    print('Time taken in seconds -', end - start)\n",
    "    \n",
    "    # print current fitness of the most likely parameter setting\n",
    "    print('iter %d. w: %s' % (generation, str(w)))\n",
    "    \n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time measurement for small brain\n",
    "\n",
    "| Number of subprocesses   |  Elapsed Time   |  Elapsed Time per subprocess  |\n",
    "|--------------------------|-----------------|-------------------------------|\n",
    "| 1                        |    39.06 s      |         39.06 s               |\n",
    "| 5                        |    42.63 s      |          8.52 s               |\n",
    "| 10                       |    44.72 s      |          4.47 s               |\n",
    "| 20                       |    49.58 s      |          2.48 s               |\n",
    "| 30                       |    66.34 s      |          2.21 s               |\n",
    "| 40                       |    73.10 s      |          1.83 s               |\n",
    "| 50                       |    92.97 s      |          1.86 s               |\n",
    "| 80                       |   149.80 s      |          1.87 s               |\n",
    "|100                       |   188.15 s      |          1.88 s               |\n",
    "|200                       |   382.65 s      |          1.91 s               |\n",
    "|300                       |   592.33 s      |          1.97 s               |\n",
    "|500                       |   993.66 s      |          1.99 s               |\n",
    "|800                       |  1599.73 s      |          1.99 s               |"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
