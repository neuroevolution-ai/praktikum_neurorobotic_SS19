{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN to SNN conversion\n",
    "\n",
    "In this notebook we try to import an ANN (\"analog neural network\", a regular non-spiking network) and convert it to a SNN (spiking neural network). \n",
    "\n",
    "For this we have generated some an ANN using [this](https://github.com/spikingevolution/evolution-strategies/blob/master/evolution-strategies.ipynb) jupyter notebook. We picked a snapshot of it and saved it as `snapshot_00423.h5`. We use this network as our input. We will convert this network into a an equivalent SNN. And then we will execute both networks and see how they compare. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## roadmap / todo\n",
    "\n",
    "- [ ] first we rebuild this docker-container and install SNN-toolbox\n",
    "- [ ] then we copy the snnToNest example from [the official snn_toolbox repository](https://github.com/NeuromorphicProcessorProject/snn_toolbox/blob/master/examples/mnist_keras_nest.py). We use that script as a base\n",
    "- [ ] generate a better ANN model. (The current one just stands still and does nothing)\n",
    "- [ ] import the snapshot and convert it to a SNN\n",
    "- [ ] run this SNN using PyNN and dummy-data.\n",
    "- [ ] install the runtime-environment which we need to run the original ANN\n",
    "- [ ] run the original ANN using the same dummy-data\n",
    "- [ ] compare both\n",
    "- [ ] install the physics environment that was used to train the ANN\n",
    "- [ ] run the original ANN using the in that environment\n",
    "- [ ] run the SNN in that environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## problems\n",
    "\n",
    "- keras' \"custom_objects\" können nicht durch toolbox verarbeitet werden. \n",
    "  - Es können lediglich eigene Aktivations geladen werden, aber auch das funktioniert eher schlecht als recht [quelle](https://github.com/NeuromorphicProcessorProject/snn_toolbox/blob/0b0b8a2bf6eac9c4d6b70bf0f54451627c2026af/snntoolbox/parsing/utils.py#L1230). \n",
    "  - Lösung: \n",
    "      - [ ] issue anlegen und fragen, ob das so richtig ist\n",
    "      - [ ] snn_toolbox clonen \n",
    "      - [ ] eigenen clone ausführen\n",
    "      - [ ] load-funktion hard-coden \n",
    "      - [ ] ausführen und beten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## potential problems\n",
    "\n",
    "- snn_toolbox has lots of parameters and optimisations. Creating an SNN that actually works may be hard\n",
    "  - solution: read paper\n",
    "- creating run both ANN and SNN concurrently requires dependancies for both. It may be a pain to set up both, and to create equivalent input for both\n",
    "  - solution: it probably takes some time\n",
    "- ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"imports for SNN Toolbox.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Conv2D, AveragePooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.datasets import mnist\n",
    "# from keras.utils import np_utils\n",
    "from tensorflow.python.keras import utils as np_utils\n",
    "\n",
    "from snntoolbox.bin.run import main\n",
    "from snntoolbox.utils.utils import import_configparser, apply_modifications\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORKING DIRECTORY #\n",
    "#####################\n",
    "\n",
    "# Define path where model and output files will be stored.\n",
    "# The user is responsible for cleaning up this temporary directory.\n",
    "path_wd = os.path.abspath(os.path.join(os.path.dirname(os.path.realpath(\n",
    "    \"snntest\")), '..', 'temp', str(time.time())))\n",
    "os.makedirs(path_wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "ann_path='snapshot_00423.h5'\n",
    "ann_name=\"example_ann\"\n",
    "target_path = os.path.join(path_wd,ann_name)\n",
    "orig_path = os.path.join(path_wd,ann_name)\n",
    "copyfile(ann_path, target_path+\".h5\")\n",
    "copyfile(os.path.join('snntest','x_test.npz'), os.path.join(path_wd,'x_test.npz'))\n",
    "copyfile(os.path.join('snntest','y_test.npz'), os.path.join(path_wd,'y_test.npz'))\n",
    "\n",
    "# for the config below\n",
    "model_name = ann_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply_modifications\n",
    "!ls snntest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SNN TOOLBOX CONFIGURATION #\n",
    "#############################\n",
    "\n",
    "# Create a config file with experimental setup for SNN Toolbox.\n",
    "configparser = import_configparser()\n",
    "config = configparser.ConfigParser()\n",
    "\n",
    "config['paths'] = {\n",
    "    'path_wd': path_wd,             # Path to model.\n",
    "    'dataset_path': path_wd,        # Path to dataset.\n",
    "    'filename_ann': model_name      # Name of input model.\n",
    "}\n",
    "\n",
    "config['tools'] = {\n",
    "    'evaluate_ann': True,           # Test ANN on dataset before conversion.\n",
    "    'normalize': True,              # Normalize weights for full dynamic range.\n",
    "     'normalize': False,    \n",
    "}\n",
    "\n",
    "config['simulation'] = {\n",
    "    'simulator': 'nest',            # Chooses execution backend of SNN toolbox.\n",
    "    'duration': 50,                 # Number of time steps to run each sample.\n",
    "    'num_to_test': 5,               # How many test samples to run.\n",
    "    'batch_size': 1,                # Batch size for simulation.\n",
    "}\n",
    "\n",
    "config['output'] = {\n",
    "    'plot_vars': {                  # Various plots (slows down simulation).\n",
    "        'spiketrains',              # Leave section empty to turn off plots.\n",
    "        'spikerates',\n",
    "        'activations',\n",
    "        'correlation',\n",
    "        'v_mem',\n",
    "        'error_t'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Store config file.\n",
    "config_filepath = os.path.join(path_wd, 'config')\n",
    "with open(config_filepath, 'w') as configfile:\n",
    "    config.write(configfile)\n",
    "    \n",
    "# RUN SNN TOOLBOX #\n",
    "###################\n",
    "\n",
    "main(config_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /home/jovyan/base_repository/temp/1573645371.7412007/"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
