{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "\n",
    "import gym\n",
    "import roboschool\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from gym import wrappers\n",
    "from ipywidgets import Video\n",
    "import ipywidgets as widgets\n",
    "from multiprocessing import Pool, Process\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load load-model.py\n",
    "def load_model(model_path):   \n",
    "    import tensorflow as tf\n",
    "\n",
    "    class Normc_initializer(tf.keras.initializers.Initializer):\n",
    "        def __init__(self, std=1.0):\n",
    "            self.std=std\n",
    "\n",
    "        def __call__(self, shape, dtype=None, partition_info=None):\n",
    "            out = np.random.randn(*shape).astype(np.float32)\n",
    "            out *= self.std / np.sqrt(np.square(out).sum(axis=0, keepdims=True))\n",
    "            return tf.constant(out)\n",
    "    \n",
    "    class ObservationNormalizationLayer(tf.keras.layers.Layer):\n",
    "        def __init__(self, ob_mean, ob_std, **kwargs):\n",
    "            self.ob_mean = ob_mean\n",
    "            self.ob_std = ob_std\n",
    "            super(ObservationNormalizationLayer, self).__init__(**kwargs)\n",
    "\n",
    "        def call(self, x):\n",
    "            return tf.clip_by_value((x - self.ob_mean) / self.ob_std, -5.0, 5.0)\n",
    "        \n",
    "        # get_config and from_config need to implemented to be able to serialize the model\n",
    "        def get_config(self):\n",
    "            base_config = super(ObservationNormalizationLayer, self).get_config()\n",
    "            base_config['ob_mean'] = self.ob_mean\n",
    "            base_config['ob_std'] = self.ob_std\n",
    "            return base_config\n",
    "        \n",
    "        @classmethod\n",
    "        def from_config(cls, config):\n",
    "            return cls(**config)\n",
    "        \n",
    "    class DiscretizeActionsUniformLayer(tf.keras.layers.Layer):\n",
    "        def __init__(self, num_ac_bins, adim, ahigh, alow, **kwargs):\n",
    "            self.num_ac_bins = num_ac_bins\n",
    "            self.adim = adim\n",
    "            # ahigh, alow are NumPy arrays when extracting from the environment, but when the model is loaded from a h5\n",
    "            # File they get initialised as a normal list, where operations like subtraction does not work, thereforce\n",
    "            # cast them explicitly\n",
    "            self.ahigh = np.array(ahigh)\n",
    "            self.alow = np.array(alow)\n",
    "            super(DiscretizeActionsUniformLayer, self).__init__(**kwargs)\n",
    "\n",
    "        def call(self, x):            \n",
    "            # Reshape to [n x i x j] where n is dynamically chosen, i equals action dimension and j equals the number\n",
    "            # of bins\n",
    "            scores_nab = tf.reshape(x, [-1, self.adim, self.num_ac_bins])\n",
    "            # This picks the bin with the greatest value\n",
    "            a = tf.argmax(scores_nab, 2)\n",
    "            \n",
    "            # Then transform the interval from [0, num_ac_bins - 1] to [-1, 1] which equals alow and ahigh\n",
    "            ac_range_1a = (self.ahigh - self.alow)[None, :]\n",
    "            return 1. / (self.num_ac_bins - 1.) * tf.keras.backend.cast(a, 'float32') * ac_range_1a + self.alow[None, :]        \n",
    "        \n",
    "        # get_config and from_config need to implemented to be able to serialize the model\n",
    "        def get_config(self):\n",
    "            base_config = super(DiscretizeActionsUniformLayer, self).get_config()\n",
    "            base_config['num_ac_bins'] = self.num_ac_bins\n",
    "            base_config['adim'] = self.adim\n",
    "            base_config['ahigh'] = self.ahigh\n",
    "            base_config['alow'] = self.alow\n",
    "            return base_config\n",
    "        \n",
    "        @classmethod\n",
    "        def from_config(cls, config):\n",
    "            return cls(**config)\n",
    "    \n",
    "    custom_objects = {'Normc_initializer' : Normc_initializer, \n",
    "                      'ObservationNormalizationLayer' : ObservationNormalizationLayer,\n",
    "                      'DiscretizeActionsUniformLayer' : DiscretizeActionsUniformLayer}\n",
    "    \n",
    "    try:\n",
    "        model = tf.keras.models.load_model(model_path, custom_objects=custom_objects)\n",
    "    except OSError as e:\n",
    "        print(e)\n",
    "        return None\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollout_evaluation(env, model, render=False, timestep_limit=None, random_stream=None):\n",
    "    \"\"\"\n",
    "    If random_stream is provided, the rollout will take noisy actions with noise drawn from that stream.\n",
    "    Otherwise, no action noise will be added.\n",
    "    \"\"\"\n",
    "\n",
    "    env_timestep_limit = env.spec.tags.get('wrapper_config.TimeLimit.max_episode_steps')\n",
    "    timestep_limit = env_timestep_limit if timestep_limit is None else min(timestep_limit, env_timestep_limit)\n",
    "    rews = []\n",
    "    t = 0\n",
    "    ob = env.reset()\n",
    "    obs = []\n",
    "    predictions=[]\n",
    "    for _ in range(timestep_limit):\n",
    "        if render:\n",
    "            env.render()\n",
    "        obs.append(ob[None])\n",
    "        pred = model.predict_on_batch(ob[None])\n",
    "        predictions.append(pred)\n",
    "        ac = pred[0]\n",
    "        try:\n",
    "            ob, rew, done, _ = env.step(ac)\n",
    "        except AssertionError:\n",
    "            # Is thrown when for example ac is a list which has at least one entry with NaN\n",
    "            raise \n",
    "        rews.append(rew)\n",
    "        t += 1\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "    x_test = np.concatenate(obs)\n",
    "    y_test = np.concatenate(predictions)\n",
    "    np.savez_compressed('x_test', x_test)\n",
    "    np.savez_compressed('y_test', y_test)\n",
    "    return np.array(rews, dtype=np.float32), t\n",
    "\n",
    "\n",
    "def run_model(model_file_path, model_file, save_directory, record=False):   \n",
    "    \n",
    "        with open(os.path.join(model_file_path, \"config.json\"), encoding='utf-8') as f:\n",
    "            config = json.load(f)\n",
    "    \n",
    "        env = gym.make(config['config']['env_id'])\n",
    "        env.reset()\n",
    "        if record:\n",
    "            env = wrappers.Monitor(env, save_directory, force=True)\n",
    "\n",
    "        model = load_model(os.path.join(model_file_path, model_file))\n",
    "        \n",
    "        try:\n",
    "            rewards, length = rollout_evaluation(env, model)\n",
    "        except AssertionError:\n",
    "            print(\"The model file provided produces non finite numbers. Stopping.\")\n",
    "            return\n",
    "        \n",
    "        env.close()\n",
    "        print(rewards)\n",
    "        print([rewards.sum(), length])\n",
    "\n",
    "        return [rewards.sum(), length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file_path = \"/home/jovyan/base_repository/Workspace/ann_training_run/\"\n",
    "model_file_name = \"snapshot_00423.h5\"\n",
    "\n",
    "# Lets store the video file in the same directory as the model file\n",
    "save_directory = model_file_path\n",
    "\n",
    "\n",
    "#with Pool(os.cpu_count()) as pool:\n",
    "#    pool.apply(func=run_model, args=(model_file_path, model_file_name, save_directory, True))\n",
    "\n",
    "run_model(model_file_path, model_file_name, save_directory, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!sleep 2\n",
    "for file in os.listdir(save_directory):\n",
    "    if file.endswith('.mp4'):\n",
    "        video_file = os.path.join(save_directory, file)\n",
    "        print(file)\n",
    "video = Video.from_file(video_file)\n",
    "display(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
