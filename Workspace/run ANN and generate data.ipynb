{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "\n",
    "import gym\n",
    "import roboschool\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from gym import wrappers\n",
    "from ipywidgets import Video\n",
    "import ipywidgets as widgets\n",
    "from multiprocessing import Pool, Process\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load load-model.py\n",
    "def load_model(model_path):   \n",
    "    import tensorflow as tf\n",
    "\n",
    "    class Normc_initializer(tf.keras.initializers.Initializer):\n",
    "        def __init__(self, std=1.0):\n",
    "            self.std=std\n",
    "\n",
    "        def __call__(self, shape, dtype=None, partition_info=None):\n",
    "            out = np.random.randn(*shape).astype(np.float32)\n",
    "            out *= self.std / np.sqrt(np.square(out).sum(axis=0, keepdims=True))\n",
    "            return tf.constant(out)\n",
    "    \n",
    "    class ObservationNormalizationLayer(tf.keras.layers.Layer):\n",
    "        def __init__(self, ob_mean, ob_std, **kwargs):\n",
    "            self.ob_mean = ob_mean\n",
    "            self.ob_std = ob_std\n",
    "            super(ObservationNormalizationLayer, self).__init__(**kwargs)\n",
    "\n",
    "        def call(self, x):\n",
    "            return tf.clip_by_value((x - self.ob_mean) / self.ob_std, -5.0, 5.0)\n",
    "        \n",
    "        # get_config and from_config need to implemented to be able to serialize the model\n",
    "        def get_config(self):\n",
    "            base_config = super(ObservationNormalizationLayer, self).get_config()\n",
    "            base_config['ob_mean'] = self.ob_mean\n",
    "            base_config['ob_std'] = self.ob_std\n",
    "            return base_config\n",
    "        \n",
    "        @classmethod\n",
    "        def from_config(cls, config):\n",
    "            return cls(**config)\n",
    "        \n",
    "    class DiscretizeActionsUniformLayer(tf.keras.layers.Layer):\n",
    "        def __init__(self, num_ac_bins, adim, ahigh, alow, **kwargs):\n",
    "            self.num_ac_bins = num_ac_bins\n",
    "            self.adim = adim\n",
    "            # ahigh, alow are NumPy arrays when extracting from the environment, but when the model is loaded from a h5\n",
    "            # File they get initialised as a normal list, where operations like subtraction does not work, thereforce\n",
    "            # cast them explicitly\n",
    "            self.ahigh = np.array(ahigh)\n",
    "            self.alow = np.array(alow)\n",
    "            super(DiscretizeActionsUniformLayer, self).__init__(**kwargs)\n",
    "\n",
    "        def call(self, x):            \n",
    "            # Reshape to [n x i x j] where n is dynamically chosen, i equals action dimension and j equals the number\n",
    "            # of bins\n",
    "            scores_nab = tf.reshape(x, [-1, self.adim, self.num_ac_bins])\n",
    "            # This picks the bin with the greatest value\n",
    "            a = tf.argmax(scores_nab, 2)\n",
    "            \n",
    "            # Then transform the interval from [0, num_ac_bins - 1] to [-1, 1] which equals alow and ahigh\n",
    "            ac_range_1a = (self.ahigh - self.alow)[None, :]\n",
    "            return 1. / (self.num_ac_bins - 1.) * tf.keras.backend.cast(a, 'float32') * ac_range_1a + self.alow[None, :]        \n",
    "        \n",
    "        # get_config and from_config need to implemented to be able to serialize the model\n",
    "        def get_config(self):\n",
    "            base_config = super(DiscretizeActionsUniformLayer, self).get_config()\n",
    "            base_config['num_ac_bins'] = self.num_ac_bins\n",
    "            base_config['adim'] = self.adim\n",
    "            base_config['ahigh'] = self.ahigh\n",
    "            base_config['alow'] = self.alow\n",
    "            return base_config\n",
    "        \n",
    "        @classmethod\n",
    "        def from_config(cls, config):\n",
    "            return cls(**config)\n",
    "    \n",
    "    custom_objects = {'Normc_initializer' : Normc_initializer, \n",
    "                      'ObservationNormalizationLayer' : ObservationNormalizationLayer,\n",
    "                      'DiscretizeActionsUniformLayer' : DiscretizeActionsUniformLayer}\n",
    "    \n",
    "    try:\n",
    "        model = tf.keras.models.load_model(model_path, custom_objects=custom_objects)\n",
    "    except OSError as e:\n",
    "        print(e)\n",
    "        return None\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollout_evaluation(env, model, render=False, timestep_limit=None, random_stream=None):\n",
    "    \"\"\"\n",
    "    If random_stream is provided, the rollout will take noisy actions with noise drawn from that stream.\n",
    "    Otherwise, no action noise will be added.\n",
    "    \"\"\"\n",
    "\n",
    "    env_timestep_limit = env.spec.tags.get('wrapper_config.TimeLimit.max_episode_steps')\n",
    "    timestep_limit = env_timestep_limit if timestep_limit is None else min(timestep_limit, env_timestep_limit)\n",
    "    rews = []\n",
    "    t = 0\n",
    "    ob = env.reset()\n",
    "    obs = []\n",
    "    predictions=[]\n",
    "    for _ in range(timestep_limit):\n",
    "        if render:\n",
    "            env.render()\n",
    "        obs.append(ob[None])\n",
    "        pred = model.predict_on_batch(ob[None])\n",
    "        predictions.append(pred)\n",
    "        ac = pred[0]\n",
    "        try:\n",
    "            ob, rew, done, _ = env.step(ac)\n",
    "        except AssertionError:\n",
    "            # Is thrown when for example ac is a list which has at least one entry with NaN\n",
    "            raise \n",
    "        rews.append(rew)\n",
    "        t += 1\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "    x_test = np.concatenate(obs)\n",
    "    y_test = np.concatenate(predictions)\n",
    "    np.savez_compressed('x_test', x_test)\n",
    "    np.savez_compressed('y_test', y_test)\n",
    "    return np.array(rews, dtype=np.float32), t\n",
    "\n",
    "\n",
    "def run_model(model_file_path, model_file, save_directory, record=False):   \n",
    "    \n",
    "        with open(os.path.join(model_file_path, \"config.json\"), encoding='utf-8') as f:\n",
    "            config = json.load(f)\n",
    "    \n",
    "        env = gym.make(config['config']['env_id'])\n",
    "        env.reset()\n",
    "        if record:\n",
    "            env = wrappers.Monitor(env, save_directory, force=True)\n",
    "\n",
    "        model = load_model(os.path.join(model_file_path, model_file))\n",
    "        \n",
    "        try:\n",
    "            rewards, length = rollout_evaluation(env, model)\n",
    "        except AssertionError:\n",
    "            print(\"The model file provided produces non finite numbers. Stopping.\")\n",
    "            return\n",
    "        \n",
    "        env.close()\n",
    "        print(rewards)\n",
    "        print([rewards.sum(), length])\n",
    "\n",
    "        return [rewards.sum(), length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "[ 0.12351748  0.06882256  0.0278012  -0.00810214 -0.04256085 -0.085159\n",
      " -0.11875862 -0.12300464 -0.4467588   0.2162747   0.40821183  0.19353066\n",
      "  0.41742694  0.4151426   0.89326435  1.2693398   1.3222729   1.2414623\n",
      "  1.122985    1.0631046   1.0411469   1.0590436   1.012992    0.9930321\n",
      "  1.168075    1.1435043   1.1191206   1.0947015   1.0713191   1.0487375\n",
      "  1.0285765   1.0170933   1.0109234   1.0067188   1.0031165   0.99996024\n",
      "  0.99729896  0.9950045   0.99293905  0.99106914  0.9894027   0.98793274\n",
      "  0.9866433   0.9855223   0.98455924  0.9837413   0.9830554   0.98249143\n",
      "  0.98204327  0.9817085   0.9815122   0.9814897   0.9814801   0.98132026\n",
      "  0.98120445  0.98122174  0.98134655  0.9815633   0.98185813  0.98210496\n",
      "  0.98234653  0.98265713  0.98302174  0.98342776  0.98386526  0.98432636\n",
      "  0.98480487  0.98529595  0.98579574  0.986301    0.98680913  0.98731786\n",
      "  0.9878251   0.988329    0.9888279   0.98932016  0.9898043   0.99027914\n",
      "  0.9907433   0.9911957   0.9916353   0.99206144  0.9924733   0.9928703\n",
      "  0.99325186  0.99361783  0.99396795  0.99430203  0.9946201   0.9949163\n",
      "  0.99518156  0.9954329   0.99567056  0.99589485  0.9961062   0.996305\n",
      "  0.9964916   0.99666655  0.9968303   0.9969833   0.99712604  0.9972577\n",
      "  0.99737823  0.99749035  0.99759454  0.9976912   0.99778086  0.9978639\n",
      "  0.99794066  0.9980116   0.9980771   0.99813753  0.9981932   0.9982435\n",
      "  0.99829     0.998333    0.9983727   0.9984093   0.9984431   0.9984743\n",
      "  0.9985031   0.9985296   0.99855363  0.9985753   0.99859524  0.9986134\n",
      "  0.9986301   0.9986454   0.99865943  0.99867225  0.99868405  0.99869484\n",
      "  0.99870473  0.99871385  0.99872226  0.99873     0.99873716  0.9987437\n",
      "  0.9987494   0.99875456  0.99875945  0.9987639   0.99876815  0.9987721\n",
      "  0.9987758   0.99877924  0.99878246  0.99878556  0.9987884   0.9987912\n",
      "  0.99879384  0.99879634  0.9987987   0.99880105  0.99880326  0.99880534\n",
      "  0.99880743  0.9988094   0.9988113   0.99881315  0.99881494  0.99881667\n",
      "  0.99881834  0.99881995  0.99882156  0.9988231   0.9988246   0.998826\n",
      "  0.9988274   0.99882877  0.9988301   0.9988314   0.99883264  0.99883384\n",
      "  0.998835    0.99883616  0.99883723  0.9988383   0.9988393   0.99884033\n",
      "  0.9988413   0.99884224  0.99884313  0.99884397  0.9988448   0.99884564\n",
      "  0.9988464   0.9988471   0.99884784  0.99884856  0.9988492   0.99884987\n",
      "  0.99885046  0.99885106  0.9988516   0.99885213  0.99885267  0.9988532\n",
      "  0.9988537   0.9988541   0.9988546   0.998855    0.9988554   0.99885577\n",
      "  0.9988562   0.99885654  0.9988569   0.9988572   0.9988575   0.9988578\n",
      "  0.9988581   0.9988584   0.9988587   0.9988589   0.99885917  0.9988594\n",
      "  0.99885964  0.9988599   0.9988601   0.9988603   0.99886054  0.9988607\n",
      "  0.9988609   0.9988611   0.99886125  0.99886143  0.9988616   0.9988618\n",
      "  0.99886197  0.9988621   0.99886227  0.99886245  0.99886256  0.9988627\n",
      "  0.99886286  0.998863    0.99886316  0.9988633   0.9988634   0.9988635\n",
      "  0.99886364  0.9988638   0.99886394  0.99886405  0.9988642   0.9988643\n",
      "  0.9988644   0.99886453  0.99886465  0.99886477  0.9988649   0.998865\n",
      "  0.9988651   0.99886525  0.99886537  0.9988654   0.99886554  0.99886566\n",
      "  0.9988658   0.9988659   0.998866    0.99886614  0.9988662   0.9988663\n",
      "  0.99886644  0.99886656  0.9988667   0.99886674  0.99886686  0.998867\n",
      "  0.9988671   0.9988672   0.9988673   0.9988674   0.9988675   0.99886763\n",
      "  0.9988677   0.9988678   0.9988679   0.99886805  0.99886817  0.9988682\n",
      "  0.99886835  0.99886847  0.9988685   0.99886864  0.99886876  0.9988688\n",
      "  0.99886894  0.99886906  0.9988692   0.99886924  0.99886936  0.9988695\n",
      "  0.99886954  0.99886966  0.9988698   0.99886984  0.99886996  0.9988701\n",
      "  0.9988702   0.99887025  0.9988704   0.9988705   0.99887055  0.9988707\n",
      "  0.9988708   0.99887085  0.99887097  0.9988711   0.99887115  0.99887127\n",
      "  0.9988714   0.99887145  0.99887156  0.9988717   0.99887174  0.99887186\n",
      "  0.998872    0.99887204  0.99887216  0.9988723   0.99887234  0.99887246\n",
      "  0.9988725   0.99887264  0.99887276  0.9988728   0.99887294  0.99887305\n",
      "  0.9988731   0.99887323  0.9988733   0.9988734   0.99887353  0.9988736\n",
      "  0.9988737   0.9988738   0.9988739   0.998874    0.99887407  0.9988742\n",
      "  0.99887425  0.99887437  0.9988745   0.99887455  0.99887466  0.9988747\n",
      "  0.99887484  0.9988749   0.998875    0.99887514  0.9988752   0.9988753\n",
      "  0.9988754   0.9988755   0.9988756   0.9988757   0.9988758   0.99887586\n",
      "  0.998876    0.99887604  0.99887615  0.9988762   0.99887633  0.99887645\n",
      "  0.9988765   0.99887663  0.9988767   0.9988768   0.99887687  0.998877\n",
      "  0.99887705  0.99887717  0.9988772   0.99887735  0.99887747  0.9988775\n",
      "  0.99887764  0.9988777   0.9988778   0.9988779   0.998878    0.99887806\n",
      "  0.9988782   0.99887824  0.99887836  0.9988784   0.99887854  0.9988786\n",
      "  0.9988787   0.9988788   0.9988789   0.99887896  0.9988791   0.99887913\n",
      "  0.99887925  0.9988793   0.99887943  0.9988795   0.9988796   0.9988797\n",
      "  0.9988798   0.99887985  0.99887997  0.99888     0.99888015  0.9988802\n",
      "  0.9988803   0.9988804   0.99888045  0.99888057  0.9988806   0.99888074\n",
      "  0.9988808   0.9988809   0.998881    0.9988811   0.99888116  0.9988812\n",
      "  0.99888134  0.9988814   0.9988815   0.9988816   0.9988817   0.99888176\n",
      "  0.9988819   0.99888194  0.99888206  0.9988821   0.9988822   0.9988823\n",
      "  0.99888235  0.9988825   0.99888253  0.99888265  0.9988827   0.9988828\n",
      "  0.9988829   0.99888295  0.99888307  0.9988831   0.9988832   0.9988833\n",
      "  0.99888337  0.9988835   0.99888355  0.9988836   0.9988837   0.9988838\n",
      "  0.9988839   0.99888396  0.998884    0.99888414  0.9988842   0.99888426\n",
      "  0.9988844   0.99888444  0.99888456  0.9988846   0.9988847   0.9988848\n",
      "  0.99888486  0.998885    0.99888504  0.9988851   0.9988852   0.9988853\n",
      "  0.99888533  0.99888545  0.9988855   0.9988856   0.9988857   0.99888575\n",
      "  0.99888587  0.9988859   0.998886    0.9988861   0.99888617  0.9988862\n",
      "  0.99888635  0.9988864   0.99888647  0.9988866   0.99888664  0.9988867\n",
      "  0.9988868   0.9988869   0.99888694  0.998887    0.9988871   0.9988872\n",
      "  0.99888724  0.99888736  0.9988874   0.9988875   0.9988876   0.99888766\n",
      "  0.9988877   0.99888784  0.9988879   0.99888796  0.9988881   0.99888813\n",
      "  0.9988882   0.99888825  0.9988884   0.99888843  0.9988885   0.9988886\n",
      "  0.9988887   0.99888873  0.9988888   0.9988889   0.99888897  0.998889\n",
      "  0.9988891   0.9988892   0.99888927  0.9988893   0.99888945  0.9988895\n",
      "  0.99888957  0.9988896   0.99888974  0.9988898   0.99888986  0.9988899\n",
      "  0.99889     0.9988901   0.99889016  0.9988902   0.9988903   0.9988904\n",
      "  0.99889046  0.9988905   0.9988906   0.9988907   0.99889076  0.9988908\n",
      "  0.9988909   0.99889094  0.99889106  0.9988911   0.9988912   0.99889123\n",
      "  0.99889135  0.9988914   0.9988915   0.99889153  0.9988916   0.9988917\n",
      "  0.9988918   0.99889183  0.9988919   0.99889195  0.99889207  0.9988921\n",
      "  0.9988922   0.99889225  0.9988923   0.9988924   0.9988925   0.99889255\n",
      "  0.9988926   0.99889266  0.9988927   0.99889284  0.9988929   0.99889296\n",
      "  0.998893    0.9988931   0.99889314  0.99889326  0.9988933   0.9988934\n",
      "  0.99889344  0.9988935   0.99889356  0.9988937   0.99889374  0.9988938\n",
      "  0.99889386  0.9988939   0.998894    0.99889404  0.99889416  0.9988942\n",
      "  0.9988943   0.99889433  0.9988944   0.99889445  0.9988945   0.9988946\n",
      "  0.99889463  0.99889475  0.9988948   0.9988949   0.99889493  0.998895\n",
      "  0.99889505  0.9988951   0.99889517  0.9988953   0.99889535  0.9988954\n",
      "  0.99889547  0.9988955   0.9988956   0.99889565  0.9988957   0.99889576\n",
      "  0.9988958   0.99889594  0.998896    0.99889606  0.9988961   0.9988962\n",
      "  0.99889624  0.9988963   0.99889636  0.9988964   0.9988965   0.99889654\n",
      "  0.9988966   0.99889666  0.9988967   0.9988968   0.99889684  0.9988969\n",
      "  0.998897    0.9988971   0.99889714  0.9988972   0.99889725  0.9988973\n",
      "  0.9988974   0.99889743  0.9988975   0.99889755  0.9988976   0.9988977\n",
      "  0.99889773  0.9988978   0.99889785  0.9988979   0.99889797  0.998898\n",
      "  0.9988981   0.99889815  0.9988982   0.99889827  0.9988983   0.9988984\n",
      "  0.99889845  0.9988985   0.99889857  0.9988986   0.9988987   0.99889874\n",
      "  0.9988988   0.99889886  0.9988989   0.998899    0.99889904  0.9988991\n",
      "  0.99889916  0.9988992   0.9988993   0.99889934  0.9988994   0.99889946\n",
      "  0.9988995   0.9988996   0.99889964  0.9988997   0.99889976  0.9988998\n",
      "  0.9988999   0.99889994  0.9989      0.9989      0.99890006  0.9989001\n",
      "  0.9989002   0.99890023  0.9989003   0.99890035  0.9989004   0.9989005\n",
      "  0.99890053  0.9989006   0.99890065  0.9989007   0.9989008   0.99890083\n",
      "  0.9989009   0.99890095  0.99890095  0.998901    0.99890107  0.9989011\n",
      "  0.9989012   0.99890125  0.9989013   0.99890137  0.9989014   0.9989015\n",
      "  0.99890155  0.9989016   0.9989016   0.99890167  0.9989017   0.9989018\n",
      "  0.99890184  0.9989019   0.99890196  0.998902    0.998902    0.9989021\n",
      "  0.99890214  0.9989022   0.99890226  0.9989023   0.9989024   0.99890244\n",
      "  0.9989025   0.9989025   0.99890256  0.9989026   0.9989027   0.99890274\n",
      "  0.9989028   0.99890286  0.99890286  0.9989029   0.998903    0.99890304\n",
      "  0.9989031   0.99890316  0.99890316  0.9989032   0.9989033   0.99890333\n",
      "  0.9989034   0.9989034   0.99890345  0.9989035   0.9989036   0.99890363\n",
      "  0.9989037   0.9989037   0.99890375  0.9989038   0.9989039   0.99890393\n",
      "  0.99890393  0.998904    0.99890405  0.9989041   0.99890417  0.9989042\n",
      "  0.9989042   0.9989043   0.99890435  0.9989044   0.9989044   0.99890447\n",
      "  0.9989045   0.9989046   0.99890465  0.99890465  0.9989047   0.99890476\n",
      "  0.9989048   0.9989049   0.9989049   0.99890494  0.998905    0.99890506\n",
      "  0.99890506  0.9989051   0.9989052   0.99890524  0.99890524  0.9989053\n",
      "  0.99890536  0.9989054   0.9989054   0.9989055   0.99890554  0.9989056\n",
      "  0.9989056   0.99890566  0.9989057   0.9989058   0.9989058   0.99890584\n",
      "  0.9989059   0.9989059   0.99890596  0.998906    0.9989061   0.9989061\n",
      "  0.99890614  0.9989062   0.9989062   0.99890625  0.9989063   0.9989064\n",
      "  0.9989064   0.99890643  0.9989065   0.9989065   0.99890655  0.9989066\n",
      "  0.9989066   0.9989067   0.99890673  0.9989068   0.9989068   0.99890685\n",
      "  0.9989069   0.9989069   0.99890697  0.998907    0.998907    0.9989071\n",
      "  0.99890715  0.99890715  0.9989072   0.99890727  0.99890727  0.9989073\n",
      "  0.9989074   0.9989074   0.99890745  0.99890745  0.9989075   0.99890757\n",
      "  0.99890757  0.9989076   0.9989077   0.9989077   0.99890774  0.9989078\n",
      "  0.9989078   0.99890786  0.9989079   0.9989079   0.998908    0.998908\n",
      "  0.99890804  0.9989081   0.9989081   0.99890816  0.99890816  0.9989082\n",
      "  0.9989083   0.9989083   0.99890834  0.9989084   0.9989084   0.99890846\n",
      "  0.99890846  0.9989085   0.9989085   0.9989086   0.99890864  0.99890864\n",
      "  0.9989087   0.9989087   0.99890876  0.9989088   0.9989088   0.9989089\n",
      "  0.9989089   0.99890894  0.99890894  0.998909    0.99890906  0.99890906\n",
      "  0.9989091   0.9989091   0.9989092   0.9989092   0.99890924  0.9989093\n",
      "  0.9989093   0.99890935  0.99890935  0.9989094   0.9989094   0.9989095\n",
      "  0.9989095   0.99890953  0.99890953  0.9989096   0.99890965  0.99890965\n",
      "  0.9989097   0.9989097   0.9989098   0.9989098   0.99890983  0.99890983\n",
      "  0.9989099   0.9989099   0.99890995  0.99890995  0.99891     0.99891\n",
      "  0.99891007  0.99891007  0.9989101   0.9989101   0.9989102   0.9989102\n",
      "  0.99891025  0.99891025  0.9989103   0.9989103   0.99891037  0.99891037\n",
      "  0.9989104   0.9989104   0.9989105   0.9989105   0.9989105   0.99891055\n",
      "  0.9989106   0.9989106   0.9989106   0.99891067  0.99891067  0.9989107\n",
      "  0.9989107   0.9989108   0.9989108   0.99891084  0.99891084  0.99891084\n",
      "  0.9989109   0.9989109   0.99891096  0.99891096  0.998911    0.998911\n",
      "  0.9989111   0.9989111   0.9989111   0.99891114  0.99891114  0.9989112\n",
      "  0.9989112   0.99891126  0.99891126  0.99891126  0.9989113   0.9989113\n",
      "  0.9989114   0.9989114   0.99891144  0.99891144  0.99891144  0.9989115\n",
      "  0.9989115   0.9989115   0.99891156  0.99891156  0.9989116   0.9989116\n",
      "  0.9989116   0.9989117   0.9989117   0.9989117   0.99891174  0.99891174\n",
      "  0.9989118   0.9989118   0.9989118   0.99891186  0.99891186  0.9989119\n",
      "  0.9989119   0.9989119   0.998912    0.998912    0.998912    0.99891204\n",
      "  0.99891204  0.99891204  0.9989121   0.9989121   0.99891216  0.99891216\n",
      "  0.99891216  0.99891216  0.9989122   0.9989122 ]\n",
      "[987.0181, 1000]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[987.0181, 1000]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_file_path = \"/home/jovyan/base_repository/Workspace/ann_training_run/\"\n",
    "model_file_name = \"snapshot_00423.h5\"\n",
    "\n",
    "# Lets store the video file in the same directory as the model file\n",
    "save_directory = model_file_path\n",
    "\n",
    "\n",
    "#with Pool(os.cpu_count()) as pool:\n",
    "#    pool.apply(func=run_model, args=(model_file_path, model_file_name, save_directory, True))\n",
    "\n",
    "run_model(model_file_path, model_file_name, save_directory, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openaigym.video.0.714.video000000.mp4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10ba9733ad6b4e51b6a1997ecfa4265b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Video(value=b'\\x00\\x00\\x00 ftypisom\\x00\\x00\\x02\\x00isomiso2avc1mp41\\x00\\x00\\x00\\x08free\\x00\\x04\\x06Rmdat\\x00\\xâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!sleep 2\n",
    "for file in os.listdir(save_directory):\n",
    "    if file.endswith('.mp4'):\n",
    "        video_file = os.path.join(save_directory, file)\n",
    "        print(file)\n",
    "video = Video.from_file(video_file)\n",
    "display(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
